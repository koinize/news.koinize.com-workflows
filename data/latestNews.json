[
  {
    "source": "Cointelegraph",
    "date": "2023-07-20T03:55:22.000Z",
    "title": "ChatGPT’s capabilities are getting worse with age, new study claims",
    "url": "https://cointelegraph.com/news/chatgpt-accurate-responses-worsened-over-time-claims-study",
    "description": "\n                \n                    <p style=\"float:right; margin:0 0 10px 15px; width:240px;\"><img src=\"https://images.cointelegraph.com/cdn-cgi/image/format=auto,onerror=redirect,quality=90,width=840/https://s3.cointelegraph.com/uploads/2023-07/e7a39b27-bd36-4905-a298-a1d8dfb1e9a8.jpg\" class=\"type:primaryImage\"></p>\n                    \n                    <p>Some of ChatGPT's responses have shown the model's accuracy deteriorated over the last few months and researchers can't figure out why.</p>\n                    <p><p>OpenAI’s artificial intelligence-powered chatbot ChatGPT seems to be getting worse as time goes on and researchers can’t seem to figure out the reason why. </p><p>In a July 18 <a href=\"https://arxiv.org/pdf/2307.09009.pdf\" target=\"_blank\" rel=\"noopener nofollow\">study</a> researchers from Stanford and UC Berkeley found ChatGPT’s newest models had become far less capable of providing accurate answers to an identical series of questions within the span of a few months. </p><p>The study’s authors couldn’t provide a clear answer as to why the AI chatbot’s capabilities had deteriorated. </p><p>To test how reliable the different models of ChatGPT were, three researchers, Lingjiao Chen, Matei Zaharia and James Zou asked ChatGPT-3.5 and ChatGPT-4 models to solve a series of math problems, answer sensitive questions, write new lines of code and conduct spatial reasoning from prompts.</p><blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">We evaluated <a href=\"https://twitter.com/hashtag/ChatGPT?src=hash&amp;ref_src=twsrc%5Etfw\">#ChatGPT</a>&#39;s behavior over time and found substantial diffs in its responses to the *same questions* between the June version of GPT4 and GPT3.5 and the March versions. The newer versions got worse on some tasks. w/ Lingjiao Chen <a href=\"https://twitter.com/matei_zaharia?ref_src=twsrc%5Etfw\">@matei_zaharia</a> <a href=\"https://t.co/TGeN4T18Fd\">https://t.co/TGeN4T18Fd</a> <a href=\"https://t.co/36mjnejERy\">https://t.co/36mjnejERy</a> <a href=\"https://t.co/FEiqrUVbg6\">pic.twitter.com/FEiqrUVbg6</a></p>&mdash; James Zou (@james_y_zou) <a href=\"https://twitter.com/james_y_zou/status/1681519439613956099?ref_src=twsrc%5Etfw\">July 19, 2023</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n<p>According to the research, in March ChatGPT-4 was capable of identifying prime numbers with a 97.6% accuracy rate. In the same test conducted in June, GPT-4’s accuracy had plummeted to just 2.4%. </p><p>In contrast, the earlier GPT-3.5 model had improved on prime number identification within the same time frame.</p><p><strong><em>Related: </em></strong><a href=\"https://cointelegraph.com/news/sec-gary-gensler-ripple-ai-strengthen-enforcement-regime\"><strong><em>SEC’s Gary Gensler believes AI can strengthen its enforcement regime</em></strong></a></p><p>When it came to generating lines of new code, the abilities of both models deteriorated substantially between March and June.</p><p>The study also found ChatGPT’s responses to sensitive questions — with some examples showing a focus on ethnicity and gender — later became more concise in refusing to answer. </p><p>Earlier iterations of the chatbot provided extensive reasoning for why it couldn’t answer certain sensitive questions. In June however, the models simply apologized to the user and refused to answer.</p><p>“The behavior of the ‘same’ [large language model] service can change substantially in a relatively short amount of time,” the researchers wrote, noting the need for continuous monitoring of AI model quality.</p><p>The researchers recommended users and companies who rely on LLM services as a component in their workflows implement some form of monitoring analysis to ensure the chatbot remains up to speed.</p><p>On June 6, OpenAI <a href=\"https://cointelegraph.com/news/openai-creates-a-new-team-to-tackle-superintelligent-ai-systems\">unveiled plans to create</a> a team that will help manage the risks that could emerge from a superintelligent AI system, something it expects to arrive within the decade.</p><p><strong><em>AI Eye: </em></strong><a href=\"https://cointelegraph.com/magazine/ai-eye-ai-content-cannibalization-problem-threads-a-loss-leader-for-ai-data/\"><strong><em>AI’s trained on AI content go MAD, is Threads a loss leader for AI data?</em></strong></a></p><template data-name=\"subscription_form\" data-type=\"crypto_biz\"></template></p>\n                \n            "
  }
]